# HausKI â€“ Skizze vNext (Rust-first, Pop!\_OS, RTX 4070 Ti)

> **âš ï¸ Hinweis:** Dieses Dokument beschreibt die **Architektur-Vision** von HausKI.
> Nicht alle hier beschriebenen Features sind bereits implementiert.
> FÃ¼r den **aktuellen Implementierungsstatus** siehe [`ist-stand-vs-roadmap.md`](ist-stand-vs-roadmap.md).

## 0) Kurzfassung

HausKI ist ein **lokaler KI-Orchestrator** mit strengem Offline-Default. Hot-Path vollstÃ¤ndig in **Rust**.
Inference: **llama.cpp** (GGUF, CUDA), **whisper-rs** (ASR), **piper-rs** (TTS). **(ğŸ”® Geplant P1)**
Wissen: **SQLite** + **tantivy+hnsw** (leicht) â†’ optional **Qdrant** via Feature. **(ğŸ”® Geplant P2)**
UX: **TUI (ratatui)**, **VS-Code-Extension**, **schlankes Obsidian-Plugin**. **(ğŸ”® Geplant P3)**
Policies regeln lokalâ†”Cloud. **GPU-Scheduler** + **CPU-Fallback** sichern Realtime. **(ğŸ”® Geplant P2)**
Neu: `trait VectorStore`, `audio/profiles.yaml`, **Wasm-Default** fÃ¼r riskante Adapter, **harte p95/p99-Budgets**. **(ğŸ”® Geplant P1-P2)**

---

## 1) Funktionen (Was HausKI tut)

### 1.1 Orchestrator & System

* **Policy-Router** lokalâ†”Cloud (Default: lokal; Kriterien: PrivatsphÃ¤re, Kosten, Latenz, QualitÃ¤tsziel).
* **GPU-Scheduler**: VRAM-Quoten, Power-Caps, PrioritÃ¤ten (interaktiv > Batch), Thermik-WÃ¤chter.
* **Fallbacks**: bei VRAM/Hitze â†’ CPU-Inference (candle/int8).
* **Health-Daemon**: journald-Triage, Paket-Drift, Self-Heal-Hints, Snapshots/Restore.

### 1.2 GedÃ¤chtnis & Live-Kommentar

* **Memory-Schichten**: `short_term`, `working_context`, `long_term` (TTL, Pins, Themen-Buckets).
* **On-the-fly-Kommentierung** (VS Code/Obsidian): Î”-Schwelle, Cooldowns, Spam-Bremse.
* **Konflikt-Detektor**: erkennt widersprÃ¼chliche Notizen, verlinkt Quellen.
* **Modus â€Prof. Dr. Kranichâ€œ**: Gegenposition + sichtbarer Unsicherheitsgrad (âˆ´fore).

### 1.3 Obsidian / Canvas

* **Textâ†’Knoten**, Auto-Layout, DomÃ¤nen-Farben.
* **Mindmapception**: Sub-Canvas mit Backlinks.
* **Graph-Lint & Canvas-Diff**: Duplikate, Waisen, Unbalance, tote Verweise.
* **Semantische Suche** (Hybrid Vektor+Symbolik) & **Narrativ-Generator** (Briefing/PRD/Pitch).

### 1.4 Code & DevOps

* **PR-Drafter**: Titel, Changelog, Testplan, Reviewer-Checkliste.
* **Review-Copilot (lokal)**: Semgrep-Heuristiken, Leak-Check, Policy-Hints.
* **CI/CD-Kurator**: Caches, Matrix, Concurrency, Smoke-Tests-VorschlÃ¤ge.
* **Repo-Navigator**: â€ErklÃ¤re Init-Sequenzâ€œ, â€Finde Event-Store-Zugriffeâ€œ.

### 1.5 Audio (MOTU M2)

* **Profile**: Hi-Fi (Qobuz), Unterricht (Loopback+Mic), Aufnahme (Low-Latency).
* **ASR lokal**: Whisper (GPU), SRT/Markdown mit Timestamps.
* **Luthier-Agent**: Akkord/Tempo-Skizzen, Ãœbungs-Marker.
* **TTS**: Piper lokal.
* **Wake-Word** (optional, prozess-separiert, ohne Cloud).

### 1.6 Kommunikation (Adapter optional)

* **Mail**: IMAP-Pull (mbsync â†’ Maildir), Zusammenfassungen, Antwort-EntwÃ¼rfe; ICS-Extraktion.
* **Messenger** (Feature-Flags): Matrix, Signal (signal-cli), Telegram.
* **Smart-Benachrichtigungen**: Entscheidungen/Fristen erkennen; Threads â†” Obsidian-Knoten verknÃ¼pfen.
* **RSS lokal**: Repo-Commits, News, Kalenderfeeds.

### 1.7 Weltgewebe-Bridge

* **GeoJSON-Exporter** (Knoten/FÃ¤den; Sichtbarkeitsstufen).
* **NATS-Publisher** (Subjects `hauski.*` â†’ JetStream).
* **â€Cui Bonoâ€œ-PrÃ¼fer**: markiert Machtannahmen/Interessen.

### 1.8 Sicherheit

* **No-Leak-Guard**: Egress **deny-by-default**, Whitelist je Ziel.
* **KMS-mini**: `rage` (age) + **Audit-Signaturen** (append-only JSON-Lines).
* **RBAC**: Admin/Operator/Gast.
* **Sandboxing**: systemd cgroups/Namespaces; **Default: Wasm (wasmtime)** fÃ¼r Fremd-Adapter.

---

## 2) Technik (Wie das zusammenhÃ¤ngt)

### 2.1 Architektur (ASCII)

```
Clients (TUI â€¢ VSCode â€¢ Obsidian â€¢ CLI â€¢ Audio â€¢ Comm)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ core/ (axum)             â”‚  API, Policies, Auth
â”‚ event/ (async-nats)      â”‚  Subjects, Codecs
â”‚ security/                â”‚  rage(age), audit
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚         â”‚
   indexd/    daemon/        bridge/
 (SQLite+     (backup,       (GeoJSON,
  vector)      audio,         NATS)
               comm,
               comment)
      â”‚
      â–¼
 llm/ (llama.cpp FFI) â€¢ asr/ (whisper-rs) â€¢ tts/ (piper-rs)
```

### 2.2 Module (Crates)

**âœ… Implementiert:**
* `core/` (axum API, Policy-Engine, Auth, HTTP-Endpoints)
* `indexd/` (In-Memory-Index mit Substring-Suche, Namespace-Support)
* `memory/` (SQLite Key-Value-Store, TTL, Pin/Unpin-Mechanismus)
* `policy/` (Policy-Datenstrukturen)
* `policy_api/` (Policy-API-Layer, optional `heimlern` Feature)
* `cli/` (clap-basierte CLI-Tools)
* `embeddings/` (Basis-Struktur)

**ğŸ”® Geplant:**
* `indexd/` â†’ SQLite + **`trait VectorStore`**: backends `tantivy+hnsw` | `qdrant` **(P2)**
* `llm/` (llama.cpp-Binding, Token-Budget, Prompt-Cache) **(P1)**
* `asr/`, `tts/`, `audio/` (PipeWire-Profile via `profiles.yaml` + CLI-Fassade) **(P1-P2)**
* `commentary/` (Live-Kommentare, Î”-Heuristik) **(P2)**
* `bridge/` (JetStream + GeoJSON, Weltgewebe-Integration) **(P3)**
* `observability/` (erweiterte Metriken, GPU-Tracking, Budget-Guards) **(P2)**
* `adapters/*` (optional, **Wasm-Sandbox**, per Feature-Flag) **(P2)**

---

## 3) APIs & CLI

**APIs** (axum, OpenAI-kompatibel):

* `POST /v1/chat` (Stub, liefert `501` bis zur LLM-Anbindung), `POST /v1/embeddings` *(geplant)*
* `POST /asr/transcribe`, `/obsidian/canvas/suggest`, `/code/pr/draft`
* `GET /health`, `/metrics` (Prometheus)

**CLI (Auszug)**

```
hauski models pull llama3.1-8b-q4
hauski asr transcribe in.wav --model medium --out out.srt
hauski obsidian link --vault ~/Vault --auto
hauski pr draft --repo ~/weltgewebe-repo
hauski comm mail sync --inbox
hauski policy set routing.local_required=true
hauski audio profile set hifi-qobuz
```

---

## 4) Betrieb & QualitÃ¤t

### 4.1 KPIs (harte Budgets)

* **LLM p95** < 400 ms (8B, kurze Antworten)
* **Index Top-k 20** < 60 ms lokal
* **ASR WER** â‰¤ 10 % (Studio)
* **GPU-Thermik** < 80 Â°C, dGPU â‰¤ 220 W (ASR/LLM-Mix)
* **Kommentar-Signal** â‰¥ 80 % nicht weggeklickt

### 4.2 Risiken & Abwehr

* Over-Notification â†’ Î”-Schwelle, Cooldowns, Quiet-Mode
* Modell-Drift â†’ versionierte `policies/` + `models.yml`, Canary-Rollouts
* Thermik/Energie â†’ Scheduler, Nacht-Batches, Power-Limits
* API-BrÃ¼che (Signal/Telegram) â†’ Adapter hinter Trait, e2e-Tests isoliert, **Wasm-Default**

---

## 5) Sicherheit & Sandbox (konkret)

* **Egress**: deny-by-default, Whitelist per `policies/routing.yaml`
* **Runner-Isolation**: eigene cgroup/Namespace; riskante Adapter **nur** in Wasm (Capability-Filter)
* **Audits**: signierte JSON-Lines (Hash-Kette), `audit verify`
* **Lieferkette**: SBOM (Syft) + cosign-Signierung

---

## 6) Roadmap

* **P1 (jetzt)**: Core+LLM+ASR+TTS Â· Whisperâ†’Obsidian-Auto-Links Â· PR-Drafter Â· Audio-Profile Â· No-Leak-Guard Â· TUI Basis Â· **Budget-Guards**
* **P2 (6â€“10 Wo.)**: Memory-Schichten Â· Graph-Lint & Canvas-Diff Â· On-the-fly-Kommentar Â· Mail/Matrix Â· RSS Â· **GPU-Power-Caps**
* **P3**: Bridge (GeoJSON/NATS) Â· CI/CD-Kurator Â· Luthier-Agent Â· Qdrant-Option Â· Wake-Word v2 (personenabhÃ¤ngig)

---

## 7) Konfiguration (Beispiele)

**`models.yml`**

```yaml
models:
  - id: llama3.1-8b-q4
    path: /opt/models/llama3.1-8b-q4.gguf
    vram_min_gb: 6
    canary: false
  - id: whisper-medium
    path: /opt/models/whisper-medium.bin
    vram_min_gb: 4
    canary: true
```

**`policies/routing.yaml`**

```yaml
egress:
  default: deny
  allow:
    - https://api.matrix.example
routing:
  prefer_local: true
  quality_target: balanced
  cloud_fallback:
    enabled: false
    only_if:
      - "task == 'ocr' && size_mb > 200"
```

**`audio/profiles.yaml`**

```yaml
profiles:
  hifi-qobuz:
    samplerate: 96k
    loopback: false
    loudness: off
  unterricht:
    samplerate: 48k
    loopback: true
    mic_gain_db: 6
  aufnahme:
    samplerate: 48k
    latency_ms: 5
    loopback: false
```

---

## Essenz (verdichtet)

Alles Rust im Hot-Path, **Offline-Default**, **VectorStore als Trait**, **Adapter in Wasm**, **Audio via Profile**, **harte Budgets** in Code+CI. Schnell, robust, erweiterbar.

## Ironische Auslassung

Wenn PipeWire wieder Launen hat, Ã¼bernimmt die CLI â€“ und Piper spricht seelenruhig weiter.

## Gewissheitsanalyse (âˆ´fore)

* **Unsicherheitsgrad:** â— niedrigâ€“mittel
* **Ursachen:** PipeWire-APIs, FFI-Release-Drift (llama/whisper/piper), Messenger-API-VolatilitÃ¤t
* **Meta-Reflexion:** Produktiv/systembedingt â€“ Kern stabil, RÃ¤nder beweglich; Budgets+Sandbox begrenzen SchÃ¤den.

## Leitfragen

* *War dies die kritischstmÃ¶gliche ErÃ¶rterung?*
  Fast.
  **Kontrastvektor:** Eine strikt â€candle-onlyâ€œ LLM-Variante wÃ¤re puristischer, aktuell jedoch latenz- und reife-kritisch.
  **Negationsprojektion:** HÃ¤rteste Gegenposition: â€Alles in Docker-Microservices, Hot-Path egal, Hauptsache Features.â€œ â€“ bricht mit *Performanz > Zukunft > WG-KompatibilitÃ¤t*.
  **Auditmarker:** Der **Wasm-Default** fÃ¼r Adapter ist kompromisslos â€“ bewusst gewÃ¤hlt zugunsten Supply-Chain-Sicherheit trotz kleinem Overhead.
